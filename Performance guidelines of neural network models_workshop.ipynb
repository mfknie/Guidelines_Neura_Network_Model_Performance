{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Performance guidelines of neural network models_workshop.ipynb","provenance":[{"file_id":"1fHo4uikW2Mce-YJog7wYam5rKqbxK9yF","timestamp":1583851780838}],"authorship_tag":"ABX9TyPSOvYEQoBeKXn8XEQ5NUKr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gMXSE1nJQyWa"},"source":["### **Workshop Structure**\n","This workshop use a deep neural network for classification as an example, focusing on how to tweak the neural networks in order to extract the maximum accuracy out of them.\n","\n","We will see the three major parts spanned in this notebook:\n","\n","* We will be covering the practical aspects of deep learning. We will see how to split the training, validation and test sets from the given data. We will also be covering topics like regularization, dropout, normalization, etc. that help us make our model more efficient.\n","* We will discuss the concept of a mini-batch gradient descent and a few more optimizers like Momentum, RMSprop, and ADAM.\n","* We will see how different hyperparameters can be tuned to improve the model’s efficiency. We will also cover the concept of Batch Normalization and how to solve a multi-class classification challenge."]},{"cell_type":"markdown","metadata":{"id":"mJQOU67Vh1YJ"},"source":["## An example\n","We are going to work with feed-forward networks similar to the picture adopted from Wikimedia below.\n","![ Diagram of a Convolutional Neural Network](https://drive.google.com/uc?id=1l_2U8B6rjMEd86GI9f4OLGH8Ih6K00EY)"]},{"cell_type":"markdown","metadata":{"id":"inmn_ARJjTtf"},"source":["The image shows you that you feed an image as an input to the network, which goes through multiple convolutions, subsampling, a fully connected layer and finally outputs something.\n","<br><br>\n","#### The Fashion-MNIST dataset\n","Fashion-MNIST is similar to the MNIST dataset that collects Zalando's article images, with 28x28 grayscale images of 70,000 fashion products from 10 categories, and 7,000 images per category. The training set has 60,000 images, and the test set has 10,000 images."]},{"cell_type":"markdown","metadata":{"id":"2htkJLptgATg"},"source":["### Loading and preparing the data"]},{"cell_type":"code","metadata":{"id":"9OlJMmG9lIye"},"source":["## Load the data\n","from keras.datasets import fashion_mnist\n","(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCfRKIlGljJw"},"source":["## Analyze the data\n","import numpy as np\n","from keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","print('Training data shape : ', train_X.shape, train_Y.shape)\n","print('Testing data shape : ', test_X.shape, test_Y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVjE0WPomaHi"},"source":["### Visualize the image examples\n","\n","plt.figure(figsize=[5,5])\n","\n","# Display the last image in training data\n","plt.subplot(121)\n","plt.imshow(train_X[0,:,:], cmap='gray')\n","plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n","\n","# Display the last image in testing data\n","plt.subplot(122)\n","plt.imshow(test_X[0,:,:], cmap='gray')\n","plt.title(\"Ground Truth : {}\".format(test_Y[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VBzynNlNm7Y6"},"source":["The output of above two plots look like boots, and this class is assigned a class label of 9. Similarly, other fashion products will have different labels, but similar products will have same labels. "]},{"cell_type":"markdown","metadata":{"id":"5eQjijtCKatP"},"source":["#### **Labels**\n","Each training and test example is assigned to one of the following labels:\n","\n","| Label | Description |\n","| --- | --- |\n","| 0 | T-shirt/top |\n","| 1 | Trouser |\n","| 2 | Pullover |\n","| 3 | Dress |\n","| 4 | Coat |\n","| 5 | Sandal |\n","| 6 | Shirt |\n","| 7 | Sneaker |\n","| 8 | Bag |\n","| 9 | Ankle boot |\n"]},{"cell_type":"markdown","metadata":{"id":"CdcGn8GDndX2"},"source":["#### **Data preproessing**"]},{"cell_type":"code","metadata":{"id":"ZIGBy3mJnhxq"},"source":["## data reshaping\n","train_X = train_X.reshape(-1, 28,28, 1)\n","test_X = test_X.reshape(-1, 28,28, 1)\n","print(train_X.shape, test_X.shape)\n","\n","## Data format changing and normalization (data scaling)\n","train_X = train_X.astype('float32')\n","test_X = test_X.astype('float32')\n","train_X = train_X / 255.\n","test_X = test_X / 255.\n","\n","# Change the labels from categorical to one-hot encoding\n","train_Y_one_hot = to_categorical(train_Y)\n","test_Y_one_hot = to_categorical(test_Y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtbBEiWzpmkC"},"source":["### Split the training data into two parts, one designed for training and another one for validation. \n","### In this case, you will train the model on 80% of the training data and validate it on 20% of the remaining training data.\n","from sklearn.model_selection import train_test_split\n","train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n","print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nej40DIpqWQb"},"source":["### **A simple convolutional neural network**\n","![the network architecture](https://drive.google.com/uc?id=1BWIwxK3qmCnhvqc8qWqZkAnhWMjv4CQE)"]},{"cell_type":"code","metadata":{"id":"FOg-aZnxqbBr","executionInfo":{"status":"ok","timestamp":1605053591416,"user_tz":360,"elapsed":5752,"user":{"displayName":"Ping-Chang Lin","photoUrl":"","userId":"18103060543942074658"}}},"source":["## The images are of size 28 x 28. You convert the image matrix to an array, rescale it between 0 and 1, reshape it so that it's of size 28 x 28 x 1, and feed this as an input to the network. \n","import keras\n","from keras.models import Sequential,Input,Model\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.advanced_activations import LeakyReLU\n","\n","batch_size = 64\n","epochs = 20\n","num_classes = 10\n","#################################\n","# The neural network architecture\n","#################################\n","\n","fashion_model = Sequential()\n","fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))\n","fashion_model.add(LeakyReLU(alpha=0.1))\n","fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n","fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n","fashion_model.add(LeakyReLU(alpha=0.1))\n","fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n","fashion_model.add(LeakyReLU(alpha=0.1))                  \n","fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","fashion_model.add(Flatten())\n","fashion_model.add(Dense(128, activation='linear'))\n","fashion_model.add(LeakyReLU(alpha=0.1))   \n","fashion_model.add(Dense(num_classes, activation='softmax'))              "],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"tHoeU9QHtfym"},"source":["### Model compiling\n","#### some hyperparameters ######\n","batch_size = 64\n","epochs = 20\n","num_classes = 10\n","\n","opt = keras.optimizers.Adam(learning_rate=0.0005) ## optimizer options: see https://keras.io/api/optimizers/\n","fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt,metrics=['acc'])\n","fashion_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SA9eJMFmMXJs"},"source":["### **Understand model performance**\n","#### Train the model"]},{"cell_type":"code","metadata":{"id":"CLh3r0iVuSSO"},"source":["### It's time to train the model with Keras' fit() function\n","fashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zL_in_opuw9z"},"source":["You trained the model on fashion-MNIST for 20 epochs by observing the training accuracy and loss"]},{"cell_type":"markdown","metadata":{"id":"E2fqYzntLsXB"},"source":["### Check for overfitting\n","* We can first ensure the neural network performs well on the testing data to verify that the neural network does not overfit. <br>\n","* What is overfitting? <br>\n","<I><font color=7714e6> In machine learning, overfitting is a phenomenon where a machine learning model models the training data too well but fails to perform well on the testing data. Performing sufficiently good on testing data is considered as a kind of ultimatum in machine learning.\n"]},{"cell_type":"markdown","metadata":{"id":"btutrzCx1DWo"},"source":["![alt text](https://drive.google.com/uc?export&id=1FiZDQG5RngJb7CAa8Cp4cUr8w-YQgf1C)"]},{"cell_type":"markdown","metadata":{"id":"rahEALIJcoab"},"source":["#### How to identify if your model is overfitting?<br> \n","You can just cross check the training accuracy and testing accuracy. If training accuracy is much higher than testing accuracy then you can posit that your model has overfitted. <br>\n","You can also plot the predicted points on a graph to verify."]},{"cell_type":"markdown","metadata":{"id":"WF5KJpQ7vabm"},"source":["#### Model evauation on the test set"]},{"cell_type":"code","metadata":{"id":"bpX3yRvnvgBU"},"source":["test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n","print('Test loss:', test_eval[0])\n","print('Test accuracy:', test_eval[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHPv-sidwZjr"},"source":["## put the model evaluation into perspective and plot the accuracy and loss plots between training and validation data\n","accuracy = fashion_train.history['acc']\n","val_accuracy = fashion_train.history['val_acc']\n","loss = fashion_train.history['loss']\n","val_loss = fashion_train.history['val_loss']\n","epochs = range(len(accuracy))\n","fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(12,6))\n","\n","ax1.plot(epochs, accuracy, 'bo', label='Training accuracy')\n","ax1.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n","ax1.title.set_text('Training and validation accuracy')\n","ax1.legend()\n","#plt.figure()\n","ax2.plot(epochs, loss, 'bo', label='Training loss')\n","ax2.plot(epochs, val_loss, 'b', label='Validation loss')\n","ax2.legend()\n","ax2.title.set_text('Training and validation loss')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RMoqCQ3qdCCz"},"source":["#### A few techniques that can reduce overfitting:\n","    * Regularisation of data (L1 or L2).\n","    * Dropouts — Randomly dropping connections between neurons, forcing the network to find new paths and generalise.\n","    * Early Stopping — Precipitates the training of the neural network, leading to reduction in error in the test set."]},{"cell_type":"markdown","metadata":{"id":"U-eYcIfn9Ped"},"source":["**You can add a dropout layer to overcome the problem of overfitting to some extent. Dropout randomly turns off a fraction of neurons during the training process, reducing the dependency on the training set by some amount.**"]},{"cell_type":"markdown","metadata":{"id":"mpfxmw6QICoM"},"source":["In a CNN, each neuron produces one feature map. Since dropout spatial dropout works per-neuron, dropping a neuron means that the corresponding feature map is dropped - e.g. each position has the same value (usually 0). So each feature map is either fully dropped or not dropped at all.\n","\n","Pooling usually operates separately on each feature map, so it should not make any difference if you apply dropout before or after pooling. At least this is the case for pooling operations like maxpooling or averaging.\n","\n","However, if you actually use element-wise dropout (which seems to be set as default for tensorflow), it actually makes a difference if you apply dropout before or after pooling. However, there is not necessarily a wrong way of doing it. Consider the average pooling operation: if you apply dropout before pooling, you effectively scale the resulting neuron activations by 1.0 - dropout_probability, but most neurons will be non-zero (in general). If you apply dropout after average pooling, you generally end up with a fraction of (1.0 - dropout_probability) non-zero \"unscaled\" neuron activations and a fraction of dropout_probability zero neurons. Both seems viable to me, neither is outright wrong.\n","\n","[This tutorial](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/) uses pooling before dropout and gets good results.\n"]},{"cell_type":"code","metadata":{"id":"EhrkFY7Q9Fd3","executionInfo":{"status":"ok","timestamp":1605054657617,"user_tz":360,"elapsed":280,"user":{"displayName":"Ping-Chang Lin","photoUrl":"","userId":"18103060543942074658"}}},"source":["#################################\n","# The neural network architecture\n","#################################\n","# Adding dropout into the network\n","# sugguestion of using Dropout(rate = 0.25) in between and Dropout(rate = 0.4) before the last Dense layer\n","# below is just the copy of the cell above\n","\n","fashion_model = Sequential()\n","fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))#, kernel_regularizer=l2(0.01)))\n","fashion_model.add(LeakyReLU(alpha=0.1))\n","fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n","fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))#, kernel_regularizer=l2(0.01)))\n","fashion_model.add(LeakyReLU(alpha=0.1))\n","fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))#, kernel_regularizer=l2(0.01)))\n","fashion_model.add(LeakyReLU(alpha=0.1))             \n","fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","fashion_model.add(Flatten())\n","fashion_model.add(Dense(128, activation='linear'))\n","fashion_model.add(LeakyReLU(alpha=0.1))  \n","fashion_model.add(Dense(num_classes, activation='softmax')) "],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"to731RRfKQmC"},"source":["### Model compiling\n","#### some hyperparameters ######\n","batch_size = 64\n","epochs = 20\n","\n","opt = keras.optimizers.Adam(learning_rate=0.0005) ## optimizer options: see https://keras.io/api/optimizers/\n","fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt,metrics=['acc'])\n","fashion_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhGb6l8PKetG"},"source":["fashion_train_dropout = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1ZvnY_WLb39"},"source":["test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n","print('Test loss:', test_eval[0])\n","print('Test accuracy:', test_eval[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9O73DXxLp0G"},"source":["accuracy = fashion_train_dropout.history['acc']\n","val_accuracy = fashion_train_dropout.history['val_acc']\n","loss = fashion_train_dropout.history['loss']\n","val_loss = fashion_train_dropout.history['val_loss']\n","epochs = range(len(accuracy))\n","fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(12,6))\n","\n","ax1.plot(epochs, accuracy, 'bo', label='Training accuracy')\n","ax1.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n","ax1.title.set_text('Training and validation accuracy')\n","ax1.legend()\n","#plt.figure()\n","ax2.plot(epochs, loss, 'bo', label='Training loss')\n","ax2.plot(epochs, val_loss, 'b', label='Validation loss')\n","ax2.legend()\n","ax2.title.set_text('Training and validation loss')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZVmh_3QV2N7S"},"source":["When the input distribution to the layers of your neural network end up fluctuating. The internal part refers to the fact that this fluctuation is happening in the intermediate layers of the neural network, which can be thought of the internal part of the network. The covariate part refers to the fact that the distributions are parameterized by weights that vary with each other. Shift, well, means the distribution is changing.<br>\n","Using **Batch Normalization** to cccelerate deep network training by reducing internal covariate shift.\n"]},{"cell_type":"code","metadata":{"id":"vy_QqNAs3Tor","executionInfo":{"status":"ok","timestamp":1605054833072,"user_tz":360,"elapsed":256,"user":{"displayName":"Ping-Chang Lin","photoUrl":"","userId":"18103060543942074658"}}},"source":["#################################\n","# The neural network architecture\n","#################################\n","# Adding dropout into the network\n","# Adding batch normalization layer, which is BatchNoarmalization(), in addition to dropout, into the network\n","# sugguestion of using Dropout(rate = 0.25) in between and Dropout(rate = 0.4) before the last Dense layer\n","# below is just the copy of the cell above\n","\n","fashion_model = Sequential()\n","fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))#, kernel_regularizer=l2(0.01)))\n","fashion_model.add(LeakyReLU(alpha=0.1))\n","fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n","fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))#, kernel_regularizer=l2(0.01)))\n","fashion_model.add(LeakyReLU(alpha=0.1))\n","fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))#, kernel_regularizer=l2(0.01)))\n","fashion_model.add(LeakyReLU(alpha=0.1))             \n","fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","fashion_model.add(Flatten())\n","fashion_model.add(Dense(128, activation='linear'))\n","fashion_model.add(LeakyReLU(alpha=0.1))  \n","fashion_model.add(Dense(num_classes, activation='softmax')) "],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"3-HaNAwt4fBr"},"source":["### Model compiling\n","#### some hyperparameters ######\n","batch_size = 64\n","epochs = 20\n","\n","opt = keras.optimizers.Adam(learning_rate=0.0005) ## optimizer options: see https://keras.io/api/optimizers/\n","fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt,metrics=['acc'])\n","fashion_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cc04EHL4f5S"},"source":["fashion_train_dropout_batchnorm = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zF__-cWz4lDN"},"source":["test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n","print('Test loss:', test_eval[0])\n","print('Test accuracy:', test_eval[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ukzr62F4pz6"},"source":["accuracy = fashion_train_dropout_batchnorm.history['acc']\n","val_accuracy = fashion_train_dropout_batchnorm.history['val_acc']\n","loss = fashion_train_dropout_batchnorm.history['loss']\n","val_loss = fashion_train_dropout_batchnorm.history['val_loss']\n","epochs = range(len(accuracy))\n","fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(12,6))\n","\n","ax1.plot(epochs, accuracy, 'bo', label='Training accuracy')\n","ax1.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n","ax1.title.set_text('Training and validation accuracy')\n","ax1.legend()\n","#plt.figure()\n","ax2.plot(epochs, loss, 'bo', label='Training loss')\n","ax2.plot(epochs, val_loss, 'b', label='Validation loss')\n","ax2.legend()\n","ax2.title.set_text('Training and validation loss')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DyHuZPPlMf4b"},"source":["### Data dearth dealing\n","There are many cases where the amount of training data available is restricted. If you are not able to collect more data then you could resort to data augmentation techniques."]},{"cell_type":"markdown","metadata":{"id":"Q6nSuqvve0c2"},"source":["#### <b>Question:</b>\n","Which of the followings does data augmentation do?\n","\n","   A.  Adds more training data<br>\n","   B.  Replaces training data<br>\n","   C.  Does both<br>\n","   D.  I don’t know<br>\n"]},{"cell_type":"markdown","metadata":{"id":"SSFpJNjngJUP"},"source":["Technically, all the answers are correct — but the only way you know if a given definition of data augmentation is correct is via the context of its application.\n","\n","#### **What is data augmentation?**\n","\n","Data augmentation encompasses a wide range of techniques used to generate “new” training samples from the original ones by applying random jitters and perturbations (but at the same time ensuring that the class labels of the data are not changed).\n","\n","Our goal when applying data augmentation is to increase the generalizability of the model.\n","\n","Given that our network is constantly seeing new, slightly modified versions of the input data, the network is able to learn more robust features.\n","\n","At testing time we do not apply data augmentation and simply evaluate our trained network on the unmodified testing data "]},{"cell_type":"markdown","metadata":{"id":"t4wP-yndqMi6"},"source":["#### A simple data augmentation\n","![alt text](https://drive.google.com/uc?id=1Ne089ybJL1Bv7VmAJwYJjDwkYcx7uHEF)\n","\n","**Left:** A sample of 250 data points that follow a normal distribution exactly.<br> **Right:** Adding a small amount of random “jitter” to the distribution. This type of data augmentation increases the generalizability of our networks.<br>\n","\n","In the context of computer vision, we can obtain augmented data by applying simple geometric transforms, for example:<br>\n","*random* <br>\n","> translations<br>\n","> rotation<br>\n","> scaling<br>\n","> shearing<br>\n","> horizontal/ vertical flips\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WUPeBi07Mj9x"},"source":["### Hyperparameter tuning\n","Instead of trying different values by hand, we will use ***GridSearchCV*** from ***Scikit-Learn*** to try out several values for our hyperparameters and compare the results. <br>\n","To do cross-validation with **keras**, we will use the wrappers for the Scikit-learn API.<br>\n","There are two warppers available:\n","<font color='red'>keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_parms)</font>, which implements the Scikit-learn classifier interface,<br>\n","<font color='red'>keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params)</font>, which implemens the Scikit-learn regressor interface.\n"]},{"cell_type":"code","metadata":{"id":"YrzQC0UhMnQY"},"source":["from sklearn.model_selection import GridSearchCV\n","from keras.wrappers.scikit_learn import KerasClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BPOZ3UQVpv6j"},"source":["#### Trying different weight initializations\n","The first parameter we will try to optimized via cross-validation is different weight initializations."]},{"cell_type":"code","metadata":{"id":"Lh1VLxS1pfX1"},"source":["## Let's create a function that crteates the model while accepting the hyperparameters we want to tune\n","\n","num_classes = 10\n","#################################\n","# The neural network architecture\n","#################################\n","def create_model(init_mode = 'uniform'):\n","  model = Sequential()\n","  model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same', kernel_initializer=init_mode))\n","  model.add(LeakyReLU(alpha=0.1))\n","  model.add(MaxPooling2D((2, 2),padding='same'))\n","  model.add(Conv2D(64, (3, 3), activation='linear',padding='same', kernel_initializer=init_mode))\n","  model.add(LeakyReLU(alpha=0.1))\n","  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","  model.add(Conv2D(128, (3, 3), activation='linear',padding='same', kernel_initializer=init_mode))\n","  model.add(LeakyReLU(alpha=0.1))                  \n","  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","  model.add(Flatten())\n","  model.add(Dense(128, activation='linear', kernel_initializer=init_mode))\n","  model.add(LeakyReLU(alpha=0.1))   \n","  model.add(Dense(num_classes, activation='softmax', kernel_initializer=init_mode))    \n","  ## compile model\n","  model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=0.0005),metrics=['acc'])\n","  \n","  return model         "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8JozjR5nw4g"},"source":["seed = 8\n","batch_size = 64\n","epochs = 10\n","\n","np.random.seed(seed)\n","\n","model_CV = KerasClassifier(build_fn=create_model, epochs = epochs, batch_size = batch_size, verbose = 1)\n","## define the grid search parameters\n","init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n","param_grid = dict(init_mode = init_mode)\n","grid = GridSearchCV(estimator = model_CV, param_grid = param_grid, n_jobs=-1, cv=3)\n","grid_result = grid.fit(train_X, train_label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0u-Z5CXuxfWH"},"source":["#print results\n","print(f'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_}')\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(f' mean={mean:.4}, std={stdev:.4} using {param}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sm9isXoKyDgQ"},"source":["#### cross-validation with more than one hyperparameter\n","We can do cross-validation with more than one parameters simultaneously, effectively trying out combinations of them.<br>\n","**Note: Cross-validation in neural networks is computationally expensive.**\n"]},{"cell_type":"code","metadata":{"id":"rEpufsx-ye4X"},"source":["### Let's perform a GridSearch for batch size and initializer combined now.\n","### First, create a function that creates the model (required for KerasClassifier) \n","### while accepting the hyperparameters we want to tune \n","### we also pass some default values such as optimizer='Adam'\n","\n","def create_model2(optimizer ='Adam', init = 'glorot_uniform'):\n","  model = Sequential()\n","  model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same', kernel_initializer=init))\n","  model.add(LeakyReLU(alpha=0.1))\n","  model.add(MaxPooling2D((2, 2),padding='same'))\n","  model.add(Conv2D(64, (3, 3), activation='linear',padding='same', kernel_initializer=init))\n","  model.add(LeakyReLU(alpha=0.1))\n","  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","  model.add(Conv2D(128, (3, 3), activation='linear',padding='same', kernel_initializer=init))\n","  model.add(LeakyReLU(alpha=0.1))                  \n","  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n","  model.add(Flatten())\n","  model.add(Dense(128, activation='linear', kernel_initializer=init))\n","  model.add(LeakyReLU(alpha=0.1))   \n","  model.add(Dense(num_classes, activation='softmax', kernel_initializer=init))    \n","  ## compile model\n","  model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizer ,metrics=['acc'])\n","  \n","  return model "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXyheMPVhjPv"},"source":["seed = 8\n","batch_size = [32, 64, 128]\n","epochs = 5\n","\n","np.random.seed(seed)\n","\n","model_CV = KerasClassifier(build_fn=create_model2, epochs = epochs, verbose = 1)\n","## define the grid search parameters\n","init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n","params_grid = dict(init = init_mode, batch_size = batch_size)\n","grid = GridSearchCV(estimator = model_CV, param_grid = params_grid, n_jobs=-1, cv=3)\n","grid_result = grid.fit(train_X, train_label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwpnpGQDu9KW"},"source":["#print results\n","print(f'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_}')\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(f' mean={mean:.4}, std={stdev:.4} using {param}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqatLSsWMpEk"},"source":["### Algorithm ensemble\n","If individual neural networks are not as accurate as you want, you can create an ensemble of neural networks and combine their predictive power. For example:\n","* Choose different neural network architectures\n","* Train them on different parts of the data\n","* Ensemble them and use their collective predictive power to get high accuracy on test data. "]},{"cell_type":"code","metadata":{"id":"xnhbjkyTMsOc"},"source":["### Supposedly you are building a cats vs dogs classifier, 0-cat and 1-dog. \n","### When combining different cats vs dogs classifiers, \n","### the accuracy of the ensemble algorithm increases based on the Pearson Correlation between the individual classifiers.\n","\n","### Let's look at the example below,\n","'''\n","Ground Truth: 1111111111\n","Classifier 1: 1111111100 = 80% accuracy\n","Classifier 2: 1111111100 = 80% accuracy\n","Classifier 3: 1011111100 = 70% accuracy\n","'''\n","from scipy.stats import pearsonr as pr\n","\n","grnd_tru = [1,1,1,1,1,1,1,1,1,1]\n","clfr1 = [1,1,1,1,1,1,1,1,0,0]\n","clfr2 = [1,1,1,1,1,1,1,1,0,0]\n","clfr3 = [1,0,1,1,1,1,1,1,0,0]\n","\n","r12, __ = pr(clfr1, clfr2)\n","r13, __ = pr(clfr1, clfr3)\n","r23, __ = pr(clfr2, clfr3)\n","print('r12: %f, r13: %f, r23: %f' %(r12, r13, r23))\n","\n","### The Pearson Correlation of the three models is high. Therefore, ensembling them does not improve the accuracy. \n","### If we ensemble the above three models using a majority vote, we get the following result.\n","\n","ensemble = [int((cl1+cl2+cl3)/3 > 0.5) for cl1, cl2, cl3 in zip(clfr1, clfr2, clfr3)]\n","acc = [x == y for x, y in zip(grnd_tru, ensemble)]\n","accuracy = sum(acc)/len(acc)\n","print('accuracy =', accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUtxjKhiqZN9"},"source":["### Now let's look at three models having a very low Person Correlation between their outputs.\n","'''\n","Ground Truth: 1111111111\n","Classifier 1: 1111111100 = 80% accuracy\n","Classifier 2: 0111011101 = 70% accuracy\n","Classifier 3: 1000101111 = 60% accuracy\n","'''\n","grnd_tru = [1,1,1,1,1,1,1,1,1,1]\n","clfr1 = [1,1,1,1,1,1,1,1,0,0]\n","clfr2 = [0,1,1,1,0,1,1,1,0,1]\n","clfr3 = [1,0,0,0,1,0,1,1,1,1]\n","\n","r12, __ = pr(clfr1, clfr2)\n","r13, __ = pr(clfr1, clfr3)\n","r23, __ = pr(clfr2, clfr3)\n","print('r12: %f, r13: %f, r23: %f' %(r12, r13, r23))\n","\n","###When we ensemble these three weak learners, we get the following result.\n","ensemble = [int((cl1+cl2+cl3)/3 > 0.5) for cl1, cl2, cl3 in zip(clfr1, clfr2, clfr3)]\n","acc = [x == y for x, y in zip(grnd_tru, ensemble)]\n","accuracy = sum(acc)/len(acc)\n","print('accuracy =', accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IieSmT6h7C8J"},"source":["#### An ensemble of weak learners with low Pearson Correlation is able to outperform an ensemble with high Pearson Correlation between them."]},{"cell_type":"markdown","metadata":{"id":"ZK_j2WB7zXR8"},"source":["#### Exercise:\n","Try to optimize the present model using:\n","* overfitting reduction -- dropout, regularizer (L1/ L2), etc.\n","* data augumentation\n","* hyperparameter tuning -- grid search of hyperparameters including batch size, optimizer, weight initilization\n","* algorithm (model) ensemble"]}]}